{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Introduction to RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Suppose we are watching a movie, we keep watching the movie as at any point in time, we have the context. Because we have seen the movie until that time, then only we are able to relate everything correctly. It means that we remember everything that we have watched.\n",
    "* Similarly RNN remembers everything.\n",
    "* In other neural networks, all the inputs are independent of each other. But in RNN, all the inputs are related to each other.\n",
    "* Lets say we have to predict the next word in a given sentence, in that case, relation among all the previous words helpsin predicting the better output. RNN remembers all these relationswhile training itself.\n",
    "* In order to achieve this RNN creates networks with loopsin them, which allow it to persist the information.\n",
    "* RNN carries context/information along with the journey\n",
    "* They overcome from the drawback of feed forward neural networks i.e. they accept  a fixed sized vector as input (ex:- image) and produce a fixed sized vector as output(ex:- probabilities of different classes)\n",
    "* Ex :- \"This phone is very fast\" - here, 'fast' is related to 'phone'. 'very' is used in the context of phone and fastness.\n",
    "* Time series is also kind of sequence information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Why RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If output depends on sequence of inputs\n",
    "* To retain and levearage sequence information\n",
    "* If the input size is changing, for MNN it is tuff to handle\n",
    "* Can handle sequential data\n",
    "* Considers current input and also the previously received inputs\n",
    "* Can memorize previous inputs due to its internal memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3  Applications of RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Natural Language Processing - Text sequence information\n",
    "* Time Series data analysis - Timely sequence information\n",
    "* Machine Translation - Sequence to sequence information(variation of RNN)\n",
    "* Speech recognition - ex:- sequence in audio -> sentence in english\n",
    "* Image captioning - Image -> captions/english sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Types of RNN Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Many to one : Sentment analysis, movie rating(multiclass classification)\n",
    "* One to many : Image captioning\n",
    "* Many to many : Parts of speech detection(many to many of same length), Machine translation(many to many of different length). Also called Encoder and Decoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5  Disadvantages of RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can't take care of long term dependencies ie. if later output depends on earlier input/inputs. Ex:- machine translations\n",
    "* If the activation function is sigmoid/tanh, lots of multiplication of partial derivatives which are less than 1, results in Vanishing Gradient problem\n",
    "* If few partial derivatives are more than 1, results in Exploding Gradient problem\n",
    "* Lots of multiplication during forward/backward propagation over time results in above two problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Introduction to LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is similar to RNN. The differences are the operations within the LSTM's cells. These operations are used to allow the LSTM to keep or forget information.\n",
    "* Core concept of LSTMs are the cell state and its various gates.\n",
    "* The cell state act as a transport highway that transfers relative information all the way down the sequence chain. We can think of it as a memory of the network.\n",
    "* Cell state can carry relavent information thoughput the processing of the sequence.\n",
    "* Cell state carry infomation from earlier time steps can make its way  to latet time steps, reducing the efforts of short term memory.\n",
    "* The cell state goes on its journey, informationgets added  or removed  to the cell state via gates.\n",
    "* The gates different neural networks that decide  which information is allowed to the cell state. The gates can learn what information to keep or forget during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 LSTM Gates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Forget gate :</b><br>\n",
    "* This gate decides what information should be thrown away or kept.\n",
    "* Info from previous hidden state and info from current input  is passed though sigmoid function.\n",
    "* Values come out between 0 and 1. The closer to '0' means to forget, and closer to '1' means to keep.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Input gate :</b><br>\n",
    "* To update the cell state we have input gate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It gives good accuracy\n",
    "* It takes more time to run\n",
    "* Architecture reference : https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "* IMDB case study: https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GRU uses 2 gates ie. reset gate and update gate. Where as LSTM has 3 steps.\n",
    "* GRU doesnot have an internal memory.\n",
    "* Reset gate decides how to combine  new input with the previous time steps menory.\n",
    "* Update gate decides how much of the previous memory should be kept. Update gate is a combination of input and forget gate that we understood in LSTM.\n",
    "* GRU is simpler variant of LSTM to solve vanishing gradient problem\n",
    "* GRU is faster to compute back-propagation due to simpler network architecture\n",
    "* GRU reference : https://www.slideshare.net/hytae/recent-progress-in-rnn-and-nlp-63762080\n",
    "* GRU reference : https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. IMDB Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Reference :</b><br>\n",
    "* https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "* https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Embedding layers :</b>\n",
    "* Turns positive integers (indexes) into dense vectors of fixed size.\n",
    "e.g. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]\n",
    "* https://keras.io/api/layers/core_layers/embedding/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Xi -> sequence of words, Yi -> binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Libraries required :</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Dataset :</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference : https://keras.io/api/datasets/imdb/\n",
    "\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[1])\n",
    "print(type(X_train[1]))\n",
    "print(len(X_train[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data preparation :</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate and/or pad input sequences\n",
    "max_review_length = 600\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Model building :</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words+1, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "#Refer: https://datascience.stackexchange.com/questions/10615/number-of-parameters-in-an-lstm-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, nb_epoch=10, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Demand Forecasting using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Objective :</b><br>\n",
    "    The objective is to predict the electricity consuumption of a household with a one-minute sampling rate based on the past 4 years of consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Libraries :</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "from time import time\n",
    "\n",
    "# Suppress Scientific notations and display float up to 2 decimals\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Read Data :</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shashidhar\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (2,3,4,5,6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:24:00</td>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.840</td>\n",
       "      <td>18.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:25:00</td>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.630</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:26:00</td>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.290</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:27:00</td>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.740</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16/12/2006</td>\n",
       "      <td>17:28:00</td>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.680</td>\n",
       "      <td>15.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time Global_active_power Global_reactive_power  Voltage  \\\n",
       "0  16/12/2006  17:24:00               4.216                 0.418  234.840   \n",
       "1  16/12/2006  17:25:00               5.360                 0.436  233.630   \n",
       "2  16/12/2006  17:26:00               5.374                 0.498  233.290   \n",
       "3  16/12/2006  17:27:00               5.388                 0.502  233.740   \n",
       "4  16/12/2006  17:28:00               3.666                 0.528  235.680   \n",
       "\n",
       "  Global_intensity Sub_metering_1 Sub_metering_2  Sub_metering_3  \n",
       "0           18.400          0.000          1.000            17.0  \n",
       "1           23.000          0.000          1.000            16.0  \n",
       "2           23.000          0.000          2.000            17.0  \n",
       "3           23.000          0.000          1.000            17.0  \n",
       "4           15.800          0.000          1.000            17.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('household_power_consumption.txt', delimiter=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We need to merge 'Date' and 'Time' features into single indexed time series feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2075259 entries, 0 to 2075258\n",
      "Data columns (total 9 columns):\n",
      "Date                     object\n",
      "Time                     object\n",
      "Global_active_power      object\n",
      "Global_reactive_power    object\n",
      "Voltage                  object\n",
      "Global_intensity         object\n",
      "Sub_metering_1           object\n",
      "Sub_metering_2           object\n",
      "Sub_metering_3           float64\n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 142.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check the data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Prepare Data :</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem we will do a Univariate time series modeling using only the Global_active_power as the variable.\n",
    "So let us keep only the columns that we need, and also convert the Global_active_power to numeric\n",
    "\n",
    "1) Create a Date-Time column\n",
    "<br>2) Keep only the columns we need\n",
    "<br>3) Address missing values\n",
    "<br>4) Convert all the data to float\n",
    "<br>5) Create columns for Year, Quarter, Month, Day, Weekday to observe the trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for Date-time\n",
    "df['Datetime'] = pd.to_datetime(df.Date + ' ' + df.Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Global_active_power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-12-16 17:24:00</td>\n",
       "      <td>4.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-12-16 17:25:00</td>\n",
       "      <td>5.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-12-16 17:26:00</td>\n",
       "      <td>5.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-12-16 17:27:00</td>\n",
       "      <td>5.388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-12-16 17:28:00</td>\n",
       "      <td>3.666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Datetime Global_active_power\n",
       "0 2006-12-16 17:24:00               4.216\n",
       "1 2006-12-16 17:25:00               5.360\n",
       "2 2006-12-16 17:26:00               5.374\n",
       "3 2006-12-16 17:27:00               5.388\n",
       "4 2006-12-16 17:28:00               3.666"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the columns we need\n",
    "df = df.loc[:,['Datetime','Global_active_power']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Global_active_power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2075254</th>\n",
       "      <td>2010-11-26 20:58:00</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075255</th>\n",
       "      <td>2010-11-26 20:59:00</td>\n",
       "      <td>0.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075256</th>\n",
       "      <td>2010-11-26 21:00:00</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075257</th>\n",
       "      <td>2010-11-26 21:01:00</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075258</th>\n",
       "      <td>2010-11-26 21:02:00</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime Global_active_power\n",
       "2075254 2010-11-26 20:58:00               0.946\n",
       "2075255 2010-11-26 20:59:00               0.944\n",
       "2075256 2010-11-26 21:00:00               0.938\n",
       "2075257 2010-11-26 21:01:00               0.934\n",
       "2075258 2010-11-26 21:02:00               0.932"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datetime                   0\n",
       "Global_active_power    25979\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The missing values are denoted by \"?\". Let us check how many missing values are there in each column\n",
    "df.apply(lambda x : sum(x==\"?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datetime               0\n",
       "Global_active_power    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill all the missing values with the data from the previous row (previous minute)\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df.apply(lambda x : sum(x=='?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric\n",
    "df['Global_active_power'] = pd.to_numeric(df['Global_active_power'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the data is sorted\n",
    "df.sort_values('Datetime', inplace=True, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:24:00</th>\n",
       "      <td>4.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:25:00</th>\n",
       "      <td>5.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:26:00</th>\n",
       "      <td>5.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:27:00</th>\n",
       "      <td>5.388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:28:00</th>\n",
       "      <td>3.666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Global_active_power\n",
       "Datetime                                \n",
       "2006-12-16 17:24:00                4.216\n",
       "2006-12-16 17:25:00                5.360\n",
       "2006-12-16 17:26:00                5.374\n",
       "2006-12-16 17:27:00                5.388\n",
       "2006-12-16 17:28:00                3.666"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the Datetime column as the index\n",
    "df.set_index('Datetime', inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed file for future use\n",
    "df.to_csv('household_power_consumption_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the average Daily consumption on different time scales\n",
    "fig, ax = plt.subplots(5, figsize=(16,30))\n",
    "\n",
    "# Daily\n",
    "ax[0].plot(df['Global_active_power'].resample('D').mean())\n",
    "ax[0].set_title('Mean power resampled over Days',fontweight=\"bold\", color='g')\n",
    "\n",
    "# Weekly\n",
    "ax[1].plot(df['Global_active_power'].resample('W').mean())\n",
    "ax[1].set_title('Mean power resampled over Weeks',fontweight=\"bold\", color='g')\n",
    "\n",
    "# Monthly\n",
    "ax[2].plot(df['Global_active_power'].resample('M').mean())\n",
    "ax[2].set_title('Mean power resampled over Months',fontweight=\"bold\", color='g')\n",
    "\n",
    "# Quarterly\n",
    "ax[3].plot(df['Global_active_power'].resample('Q').mean())\n",
    "ax[3].set_title('Mean power resampled over Quarters',fontweight=\"bold\", color='g')\n",
    "\n",
    "# Yearly\n",
    "ax[4].plot(df['Global_active_power'].resample('Y').mean())\n",
    "ax[4].set_title('Mean power resampled over Years',fontweight=\"bold\", color='g')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Check if the series is Stationary</b><br>\n",
    "\n",
    "We will use the Dickey-Fuller test to check this\n",
    "\n",
    "H0: The time-series has a unit root, i.e. it is NOT stationary\n",
    "<br>H1: The time series is stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16</th>\n",
       "      <td>3.053475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-17</th>\n",
       "      <td>2.354486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-18</th>\n",
       "      <td>1.530435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-19</th>\n",
       "      <td>1.157079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-20</th>\n",
       "      <td>1.545658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Global_active_power\n",
       "Datetime                       \n",
       "2006-12-16             3.053475\n",
       "2006-12-17             2.354486\n",
       "2006-12-18             1.530435\n",
       "2006-12-19             1.157079\n",
       "2006-12-20             1.545658"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate the data at a day level\n",
    "daily_data = df.resample('D').mean()\n",
    "\n",
    "# Check if there are any NaNs in the daily data\n",
    "np.sum(daily_data.isna())\n",
    "\n",
    "# Replace the NaNs by the previous day's value\n",
    "daily_data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "daily_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to check the Stationarity\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def Stationarity_Check(timeseries):\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags used','#Observations'])\n",
    "    print(\"\\nResults of the Augmented Dickey Fuller Test : \\n\")\n",
    "    print (dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the DF test to verify the stationarity\n",
    "\n",
    "Stationarity_Check(daily_data.Global_active_power.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the p-value we can reject the Null hypothesis and conclude that the data is Stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Time series modeling using LSTM</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['Global_active_power'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.216, 5.36 , 5.374, ..., 0.688, 0.688, 0.688])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.216],\n",
       "       [5.36 ],\n",
       "       [5.374],\n",
       "       ...,\n",
       "       [0.688],\n",
       "       [0.688],\n",
       "       [0.688]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2075259, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1660207"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(data) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training/test sets\n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = data[:train_size,], data[train_size:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data in a format required for LSTM (samples, timesteps, features)\n",
    "\n",
    "def Create_Dataset(df, lookback=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(df) - lookback - 1):\n",
    "        X.append(df[i:(i+lookback), 0])\n",
    "        Y.append(df[i + lookback,0])\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 30\n",
    "X_train, Y_train = Create_Dataset(train, lookback)\n",
    "X_test, Y_test   = Create_Dataset(test, lookback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test  = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the data\n",
    "print(\"X_train : \\n\")\n",
    "print(X_train[:2])\n",
    "\n",
    "print(\"\\n\\nY_train : \\n\")\n",
    "print(Y_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shapes of the data for modeling\n",
    "print(\"X_train : \", X_train.shape)\n",
    "print(\"Y_train : \", Y_train.shape)\n",
    "print(\"\\nX_test : \", X_test.shape)\n",
    "print(\"Y_test : \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Build the LSTM Model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping # Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(100, input_shape=( X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Train the Model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "                    epochs=2, \n",
    "                    batch_size=50,\n",
    "                    validation_data=(X_test, Y_test),\n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', patience=10)],\n",
    "                    verbose=1,\n",
    "                    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Make the predictions and convert back to the original scale</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the predictions\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict  = model.predict(X_test)\n",
    "\n",
    "# Invert the predictions to original scale\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "Y_train = scaler.inverse_transform([Y_train])\n",
    "\n",
    "test_predict  = scaler.inverse_transform(test_predict)\n",
    "Y_test = scaler.inverse_transform([Y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Check the RMSE scores</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print (\"Train MAE : \", mean_squared_error(Y_train[0], train_predict[:,0]))\n",
    "print (\"Train RMSE : \", np.sqrt(mean_squared_error(Y_train[0], train_predict[:,0])))\n",
    "\n",
    "print (\"\\nTest MAE : \", mean_squared_error(Y_test[0], test_predict[:,0]))\n",
    "print (\"Test RMSE : \", np.sqrt(mean_squared_error(Y_test[0], test_predict[:,0])))\n",
    "\n",
    "Mape_train =np.mean(np.abs(Y_train[0] - train_predict[:,0])/Y_train[0])\n",
    "Mape_test =np.mean(np.abs(Y_test[0] - test_predict[:,0])/Y_test[0])\n",
    "\n",
    "print (\"\\nTrain MAPE : \", Mape_train)\n",
    "print (\"Test MAPE : \", Mape_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.title('Comparison of model loss')\n",
    "plt.plot(history.history['loss'], label='Train loss')\n",
    "plt.plot(history.history['val_loss'], label='Test loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Plot the predicted vs actual values</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = Y_test[0][:200]\n",
    "predicted = test_predict[:,0][:200]\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(actual, label='Actual')\n",
    "plt.plot(predicted, label='Predicted')\n",
    "plt.ylabel('Global_active_power', size=13)\n",
    "plt.xlabel('Time Step', size=13)\n",
    "plt.tight_layout()\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Forecasting for future time periods\n",
    "y = []\n",
    "for i in range(0,30):\n",
    "    X1 = test[len(test)-30+i:,0]\n",
    "    X1 = np.append(X1, y)\n",
    "    X1 = X1.reshape(1,1,30)\n",
    "    y1 = model.predict(X1)\n",
    "    y.append(y1)\n",
    "    print(y1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
